{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in data \n",
    "traindf = pd.read_csv('fb_kaggle_train.csv', delimiter=\",\", usecols=[1,2,3,4,5])\n",
    "trainlabels = traindf['place_id']\n",
    "\n",
    "traindf['hour'] = ( (traindf['time']+120)/60)%24+1 \n",
    "traindf['weekday'] = (traindf['time']/1440)%7+1 \n",
    "traindf['month'] = ( traindf['time'] /43800)%12+1 \n",
    "traindf['year'] = (traindf['time']/525600)+1 \n",
    "traindf['four_hour'] = (traindf['time']/240)%6+1\n",
    "traindf['acc'] = np.log10(traindf['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = np.array([490.0, 980.0, 4.0, 3.1, 2.1, 10.0, 36]) #feature weights    X = grid_train[['x', 'y', 'hour', 'weekday', 'month', 'year', 'acc']].values * weights[g_id][:7]\n",
    "traindf = traindf[['x', 'y', 'hour', 'weekday', 'month', 'year', 'acc']].values * weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "if os.path.isfile('knn_classifier.pkl'):\n",
    "    with open('knn_classifier.pkl', 'rb') as handle:\n",
    "        knn = pickle.load(handle)\n",
    "else:\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(traindf,trainlabels.values)\n",
    "    \n",
    "    with open('knn_classifier.pkl', 'wb') as handle:\n",
    "        pickle.dump(knn, handle) \n",
    "    \n",
    "#rows = np.random.choice(traindf.index.values, 2000000, replace=False)\n",
    "#sampled_df = traindf.ix[rows]\n",
    "\n",
    "#print(rows)\n",
    "#print(sampled_df)\n",
    "#knn.fit(sampled_df.iloc[:,0:4].values,np.ravel(sampled_df.iloc[:,4:].values))\n",
    "#knn.fit(train_feat[:10000],train_labels[:10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('fb_kaggle_test.csv', delimiter=\",\", usecols=[1,2,3,4])\n",
    "\n",
    "testdf['hour'] = ( (testdf['time']+120)/60)%24+1 \n",
    "testdf['weekday'] = (testdf['time']/1440)%7+1 \n",
    "testdf['month'] = ( testdf['time'] /43800)%12+1 \n",
    "testdf['year'] = (testdf['time']/525600)+1 \n",
    "testdf['four_hour'] = (testdf['time']/240)%6+1\n",
    "testdf['acc'] = np.log10(testdf['accuracy'])\n",
    "\n",
    "weights = np.array([490.0, 980.0, 4.0, 3.1, 2.1, 10.0, 36]) #feature weights    X = grid_train[['x', 'y', 'hour', 'weekday', 'month', 'year', 'acc']].values * weights[g_id][:7]\n",
    "testdf = testdf[['x', 'y', 'hour', 'weekday', 'month', 'year', 'acc']].values * weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunkSize = 1500\n",
    "end = int(1+len(testdf)/chunkSize)\n",
    "#prob = np.argsort(knn.predict_proba(testdf[:chunkSize]))\n",
    "#top3 = [item[::-1][:3] for item in prob]\n",
    "#del prob\n",
    "\n",
    "for i in range(0,end):\n",
    "    prob = np.argsort(knn.predict_proba(testdf[i*chunkSize:(i+1)*chunkSize]))\n",
    "    top3 = [item[::-1][:3] for item in prob]\n",
    "    preds = [knn.classes_[top] for top in top3]\n",
    "    #print(top3)\n",
    "    with open(\"new_kaggle_submission.csv\", \"a\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(preds)\n",
    "        f.close()\n",
    "    del prob\n",
    "    del top3\n",
    "    del preds\n",
    "    #pred = np.concatenate((pred,knn.predict(test[i*chunkSize:(i+1)*chunkSize])))\n",
    "    #prob = np.concatenate((prob,knn.predict_proba(testdf[i*chunkSize:(i+1)*chunkSize])))\n",
    "\n",
    "#This is how to extract the top three probabilities and extract predictions \n",
    "#print([prob[::-1][:3] for prob in probs])\n",
    "#print(knn.classes_[prob[4][::-1][:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8607230)\n",
      "(8607230,)\n",
      "(4, 8607230)\n"
     ]
    }
   ],
   "source": [
    "preds = np.tile(pred,(3,1))\n",
    "print(preds.shape)\n",
    "index = np.arange(len(preds[0]))\n",
    "print(index.shape)\n",
    "preds = np.vstack((index,preds))\n",
    "print(preds.shape)\n",
    "#print(preds)\n",
    "df = pd.DataFrame({\"pred\":preds[1]})\n",
    "\n",
    "#print(dog)\n",
    "\n",
    "df[\"pred\"] = df.pred.map(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           place_id\n",
      "row_id             \n",
      "0        3071064812\n",
      "1        3885244710\n",
      "2        3071064812\n",
      "3        3071064812\n",
      "4        3885244710\n",
      "5        3071064812\n",
      "6        3885244710\n",
      "7        3885244710\n",
      "8        3071064812\n",
      "9        3885244710\n",
      "10       3071064812\n",
      "11       3071064812\n",
      "12       3885244710\n",
      "13       3071064812\n",
      "14       3071064812\n",
      "15       3885244710\n",
      "16       3885244710\n",
      "17       3071064812\n",
      "18       3885244710\n",
      "19       3071064812\n",
      "20       3071064812\n",
      "21       3071064812\n",
      "22       3885244710\n",
      "23       3071064812\n",
      "24       3071064812\n",
      "25       3071064812\n",
      "26       3071064812\n",
      "27       3071064812\n",
      "28       3071064812\n",
      "29       3885244710\n",
      "...             ...\n",
      "8607200  3071064812\n",
      "8607201  3071064812\n",
      "8607202  3885244710\n",
      "8607203  3071064812\n",
      "8607204  3885244710\n",
      "8607205  3885244710\n",
      "8607206  3885244710\n",
      "8607207  3071064812\n",
      "8607208  3071064812\n",
      "8607209  3071064812\n",
      "8607210  3885244710\n",
      "8607211  4015543882\n",
      "8607212  3885244710\n",
      "8607213  3071064812\n",
      "8607214  3071064812\n",
      "8607215  3885244710\n",
      "8607216  3071064812\n",
      "8607217  3885244710\n",
      "8607218  3071064812\n",
      "8607219  3885244710\n",
      "8607220  3885244710\n",
      "8607221  3885244710\n",
      "8607222  3885244710\n",
      "8607223  3071064812\n",
      "8607224  3885244710\n",
      "8607225  3071064812\n",
      "8607226  3071064812\n",
      "8607227  3885244710\n",
      "8607228  3071064812\n",
      "8607229  3885244710\n",
      "\n",
      "[8607230 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#df[\"pred\"] = df.pred + \" \" + df.pred + \" \" + df.pred\n",
    "df.index.name = 'row_id'\n",
    "df.columns = ['place_id']\n",
    "print(df)\n",
    "df.to_csv(\"fb_sample_submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
